{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------\n",
    "# Author Wessel Olaf van Dam 09-30-2019\n",
    "#\n",
    "# Machine Learning script on practice dataset \"Iris.csv\"\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "data = pd.read_csv('iris.csv',names=names)\n",
    "\n",
    "print(dataset.describe())\n",
    "print(\"\\n\")\n",
    "print(dataset.groupby('class').size())\n",
    "\n",
    "# histograms\n",
    "dataset.hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#We will split the loaded dataset into two, 80% of which we will use to train our models \n",
    "#and 20% that we will hold back as a validation dataset. X_train and Y_train contain the\n",
    "#training data, and X_validation and Y_validation will be used later to test the performance\n",
    "#of our models\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = data.values\n",
    "# here we split the dataset out in the features (X) and the labels (Y)\n",
    "# are we able to predict Y (i.e.,type of iris), based on features (X)\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "print(X_train.shape) # This should be 0.80% of the 150 samples = 120\n",
    "print(X_validation.shape) # This will contain 0.20% of the 150 samples = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# Here we print the accuracy of each of the 6 models to see\n",
    "# which one is most accurate\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model using Support Vector Machines (SVM) has the largest estimated\n",
    "# accuracy score. Now we want to get an idea of the accuracy of the model on our validation set.\n",
    "#This will give us an independent final check on the accuracy of the best model. \n",
    "\n",
    "#We can run the SVM model directly on the validation set and summarize the results as a final accuracy score, \n",
    "#a confusion matrix and a classification report.\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "SVM = SVC(gamma='auto')\n",
    "SVM.fit(X_train, Y_train)\n",
    "predictions = SVM.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "\n",
    "#We can see that the accuracy is 0.933 or 93.3%. The confusion matrix provides \n",
    "#an indication of the two errors made. That is, model predicted Iris-virginica but\n",
    "#it actually was Iris-versicolor\n",
    "\n",
    "#Finally, the classification report provides a breakdown of each class by precision, \n",
    "#recall, f1-score and support showing excellent results (granted the validation dataset was small)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
